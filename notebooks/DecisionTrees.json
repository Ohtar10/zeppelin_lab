{"paragraphs":[{"text":"%md\n# Machine Learning\nPodemos definir Machine Learning como el arte de hacer que la máquina aprenda de una información que se le provee, de tal forma que entienda cuales son las relaciones internas de esos datos, para luego generar un modelo que nos permita predecir o hacer inferencia sobre nuevos datos del mismo tipo de tal forma que podamos determinar un posible comportamiento, camino o asociación.\n","user":"user1","dateUpdated":"2017-11-24T12:41:53+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Machine Learning</h1>\n<p>Podemos definir Machine Learning como el arte de hacer que la máquina aprenda de una información que se le provee, de tal forma que entienda cuales son las relaciones internas de esos datos, para luego generar un modelo que nos permita predecir o hacer inferencia sobre nuevos datos del mismo tipo de tal forma que podamos determinar un posible comportamiento, camino o asociación.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1511479478173_191833325","id":"20171123-232438_795741903","dateCreated":"2017-11-23T23:24:38+0000","dateStarted":"2017-11-24T12:41:53+0000","dateFinished":"2017-11-24T12:41:53+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:3723"},{"text":"%md\n# Aplicabilidad\nUna comparación interesante es que, clásicamente en tareas de desarrollo de software, se definen para el sistema una serie de reglas de negocio, que comienzan por ser los requisitos, casos de uso etc. Luego, estas reglas\ndeben ser traducidas en código fuente por un desarrollador, usualmente en sentencias if y else, que finalmente todas unidas constituyen la lógica de un programa o sistema. Por ejemplo:\n","user":"user1","dateUpdated":"2017-11-24T12:41:50+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala","editorHide":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Aplicabilidad</h1>\n<p>Una comparación interesante es que, clásicamente en tareas de desarrollo de software, se definen para el sistema una serie de reglas de negocio, que comienzan por ser los requisitos, casos de uso etc. Luego, estas reglas<br/>deben ser traducidas en código fuente por un desarrollador, usualmente en sentencias if y else, que finalmente todas unidas constituyen la lógica de un programa o sistema. Por ejemplo:</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1511527268076_165364227","id":"20171124-124108_949650326","dateCreated":"2017-11-24T12:41:08+0000","dateStarted":"2017-11-24T12:41:44+0000","dateFinished":"2017-11-24T12:41:46+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3724"},{"text":"%python\n\ndef es_seguro_prestar(sueldo, propiedades, nivel_estudios, deudas):\n    # si se gana menos de un millón de pesos\n    if sueldo < 1000000:\n        return False\n    # si las propiedades son inferiores a 30 millones\n    if propiedades < 30000000:\n        return False\n    # si no tiene alguno de estos niveles de estudios\n    if nivel_estudios not in ['profesional', 'especialización', 'maestría', 'doctorado']:\n        return False\n    # si tiene deudas superiores a 40 millones\n    if deudas > 40000000:\n        return False\n    # Entonces si le puedo prestar :)\n    return True\n\npersonas = { 'pepito': es_seguro_prestar(2000000, 28000000, 'profesional', 5000000),\n             'juanito': es_seguro_prestar(3000000, 5000000, 'especialización', 70000000),\n             'dianita': es_seguro_prestar(1200000, 30000000, 'profesional', 1000000),\n             'jorgito': es_seguro_prestar(900000, 800000, 'profesional', 0),\n             'johanita': es_seguro_prestar(6000000, 28000000, 'maestría', 600000),\n             'julito': es_seguro_prestar(9000000, 48000000, 'doctorado', 2000000)\n             }\n\nfor p, r in personas.items():\n    resultado = 'No'\n    if r:\n        resultado = 'Sí'\n    \n    print \"Le prestamos a %s?.....%s\" % (p, resultado)\n\n","user":"user1","dateUpdated":"2017-11-24T00:18:37+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Le prestamos a pepito?.....No\nLe prestamos a johanita?.....No\nLe prestamos a julito?.....Sí\nLe prestamos a dianita?.....Sí\nLe prestamos a jorgito?.....No\nLe prestamos a juanito?.....No\n"}]},"apps":[],"jobName":"paragraph_1511479487474_-1809245705","id":"20171123-232447_732243383","dateCreated":"2017-11-23T23:24:47+0000","dateStarted":"2017-11-24T00:18:37+0000","dateFinished":"2017-11-24T00:18:37+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3725"},{"text":"%md\n# ¿Y cual es el problema?\nPues muchos\n* La lógica es estática, asi los valores se puedan almacenar aparte, sigue siendo eståtico\n* Dependemos del desarrollador todo el tiempo\n* No es extensible ni responde a cambios en el contexto\n* Es costoso mantener la función.\n \n### ¿Que propuestas hay en ese caso? .... Machine Learning al rescate!\n#### El propósito de implementar una solución de este tipo basado en machine learning es evitar estos por menores mencionados anteriormente, haciendo que el programa no solo genere un resultado por nosotros sino que también genere los \"if\" y \"else\" por nosotros. \nPara que esto funcione, es necesario contar con datos historicos que nos permitan observar los acontecimientos, propiedades y resultados y obtener un \"modelo\" que nos permita predecir que puede llegar a pasar con nuevas instancias de esos datos.","user":"user1","dateUpdated":"2017-11-24T16:45:44+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>¿Y cual es el problema?</h1>\n<p>Pues muchos<br/>* La lógica es estática, asi los valores se puedan almacenar aparte, sigue siendo eståtico<br/>* Dependemos del desarrollador todo el tiempo<br/>* No es extensible ni responde a cambios en el contexto<br/>* Es costoso mantener la función.</p>\n<h3>¿Que propuestas hay en ese caso? &hellip;. Machine Learning al rescate!</h3>\n<h4>El propósito de implementar una solución de este tipo basado en machine learning es evitar estos por menores mencionados anteriormente, haciendo que el programa no solo genere un resultado por nosotros sino que también genere los &ldquo;if&rdquo; y &ldquo;else&rdquo; por nosotros.</h4>\n<p>Para que esto funcione, es necesario contar con datos historicos que nos permitan observar los acontecimientos, propiedades y resultados y obtener un &ldquo;modelo&rdquo; que nos permita predecir que puede llegar a pasar con nuevas instancias de esos datos.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1511482690133_2091908331","id":"20171124-001810_487414386","dateCreated":"2017-11-24T00:18:10+0000","dateStarted":"2017-11-24T16:45:33+0000","dateFinished":"2017-11-24T16:45:33+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3726"},{"text":"%md\n## Ejemplo con Apache Spark ![Alt](https://www.infoq.com/resource/articles/apache-spark-machine-learning/en/smallimage/Spark-MLib.jpg \"Spark\")\n\nApache Spark es un framework para el procesamiento distribuido de grandes volumenes de datos, facilita enormemente el llevar un programa y los datos a un grupo de máquinas de tal forma que un conjunto de datos enorme pueda ser procesado en paralelo por estas.\n\nSpark contiene ademas un módulo dedicado a Machine Leraning (MLib) el cual consta de varias implementaciones de algoritmos conocidos sobre este tema como DecisionTrees, KMeans, NaiveBayes, RecommenderSystems, LinearRegression entre otros. Esto facilita enromemente el trabajo pues las implementaciones de estos suelen ser bastante complejas, además de que estas implementaciones están ya diseñadas para trabajar optimamente dentro del paradigma distribuido de Spark.\n\n### Árboles de Decisión\nUna posible forma de afrontar este problema es entonces la técnica de árboles de decisión, la cual consiste en construir, naturalmente un árbol, cuyas ramas representan un atributo y valor particulares que según un análisis de ganancias y entropía pueden hacer que la **decisión** se incline a una **clase** u otra, visualmente se podría obtener en algo como:\n![Alt](https://www.edureka.co/blog/wp-content/uploads/2015/01/tree2.png \"Decision\")\n\nNaturalmente este árbol puede representarse en sentencias If y Else por lo que se convierte en una herramienta muy útil para nuestro objetivo particular.\n\n#### ¿Cómo funciona?\nComo se mencionó antes, se parte de un conjunto de datos historico que contiene una serie de atributos (features) y un resultado (label o clase) que nos permite extraer información estadística de que valores pueden influenciar mas a que cierta clase se de, esto se realiza usualmente mediante el cálculo de la entropía de las clases y la entropía de cada atributo para hallar seleccionar el de mayor pureza o aquel atributo que mejor explica la decisión.\n\nVer: http://www.csun.edu/~twang/595DM/Slides/Week4.pdf\n\n\nPara este ejemplo, utilizaremos un conjunto de datos de prueba con estructura similar a la anterior, con la diferencia de que por simplicidad, todos los valores seran numericos:\n","user":"user1","dateUpdated":"2017-11-24T15:33:07+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>Ejemplo con Apache Spark <img src=\"https://www.infoq.com/resource/articles/apache-spark-machine-learning/en/smallimage/Spark-MLib.jpg\" alt=\"Alt\" title=\"Spark\" /></h2>\n<p>Apache Spark es un framework para el procesamiento distribuido de grandes volumenes de datos, facilita enormemente el llevar un programa y los datos a un grupo de máquinas de tal forma que un conjunto de datos enorme pueda ser procesado en paralelo por estas.</p>\n<p>Spark contiene ademas un módulo dedicado a Machine Leraning (MLib) el cual consta de varias implementaciones de algoritmos conocidos sobre este tema como DecisionTrees, KMeans, NaiveBayes, RecommenderSystems, LinearRegression entre otros. Esto facilita enromemente el trabajo pues las implementaciones de estos suelen ser bastante complejas, además de que estas implementaciones están ya diseñadas para trabajar optimamente dentro del paradigma distribuido de Spark.</p>\n<h3>Árboles de Decisión</h3>\n<p>Una posible forma de afrontar este problema es entonces la técnica de árboles de decisión, la cual consiste en construir, naturalmente un árbol, cuyas ramas representan un atributo y valor particulares que según un análisis de ganancias y entropía pueden hacer que la <strong>decisión</strong> se incline a una <strong>clase</strong> u otra, visualmente se podría obtener en algo como:<br/><img src=\"https://www.edureka.co/blog/wp-content/uploads/2015/01/tree2.png\" alt=\"Alt\" title=\"Decision\" /></p>\n<p>Naturalmente este árbol puede representarse en sentencias If y Else por lo que se convierte en una herramienta muy útil para nuestro objetivo particular.</p>\n<h4>¿Cómo funciona?</h4>\n<p>Como se mencionó antes, se parte de un conjunto de datos historico que contiene una serie de atributos (features) y un resultado (label o clase) que nos permite extraer información estadística de que valores pueden influenciar mas a que cierta clase se de, esto se realiza usualmente mediante el cálculo de la entropía de las clases y la entropía de cada atributo para hallar seleccionar el de mayor pureza o aquel atributo que mejor explica la decisión.</p>\n<p>Ver: <a href=\"http://www.csun.edu/~twang/595DM/Slides/Week4.pdf\">http://www.csun.edu/~twang/595DM/Slides/Week4.pdf</a></p>\n<p>Para este ejemplo, utilizaremos un conjunto de datos de prueba con estructura similar a la anterior, con la diferencia de que por simplicidad, todos los valores seran numericos:</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1511485508318_1339922325","id":"20171124-010508_1827700825","dateCreated":"2017-11-24T01:05:08+0000","dateStarted":"2017-11-24T15:33:07+0000","dateFinished":"2017-11-24T15:33:07+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3727"},{"text":"%python\nfrom itertools import islice\n\nwith open('/zeppelin/datasets/creditos.csv', 'r') as archivo:\n    for line in islice(archivo, 10):\n        print line\n","user":"user1","dateUpdated":"2017-11-24T14:17:25+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"1274,6994,1,23154,1\n\n6761,99902,3,86257,1\n\n5925,26250,2,49897,0\n\n5577,69034,0,65351,1\n\n7427,87932,1,31691,0\n\n5366,67421,2,16723,0\n\n2520,35881,2,55883,1\n\n6433,55274,4,29544,1\n\n8912,70206,4,21600,1\n\n1201,96980,4,96210,0\n\n"}]},"apps":[],"jobName":"paragraph_1511483679507_-1456055558","id":"20171124-003439_1342603246","dateCreated":"2017-11-24T00:34:39+0000","dateStarted":"2017-11-24T14:17:25+0000","dateFinished":"2017-11-24T14:17:25+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3728"},{"text":"%spark.pyspark\n\nfrom pyspark.mllib.regression import LabeledPoint\nfrom pyspark.mllib.tree import DecisionTree\nfrom numpy import array\n\n# Simplemente convertimos cada linea en su respectivo dato numerico que nos interesa para poder entrenar y usar el modelo\ndef convertirLineas(line):\n    fields = line.split(',')\n    salario = int(fields[0])\n    propiedades = int(fields[1])\n    educacion = int(fields[2])\n    deudas = int(fields[3])\n    presta = int(fields[4])\n    return LabeledPoint(presta, array([salario, propiedades, educacion, deudas]))\n\nrdd = sc.textFile('/zeppelin/datasets/creditos.csv')\nrdd.take(5)\n\nentrenamiento, prueba = rdd.randomSplit(weights=[0.7, 0.3], seed=1)\n\nentrenamiento = entrenamiento.map(convertirLineas)\nvalidar = prueba.map(convertirLineas)\nprueba = validar.map(lambda x: x.features)\n\nmodel = DecisionTree.trainClassifier(entrenamiento,\n                                    numClasses=2, \n                                    categoricalFeaturesInfo={2:5}, \n                                    impurity='entropy', \n                                    maxDepth=5, \n                                    maxBins=32)\n\n    ","user":"user1","dateUpdated":"2017-11-24T15:00:28+0000","config":{"colWidth":6,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1511485709968_452948059","id":"20171124-010829_1334218696","dateCreated":"2017-11-24T01:08:29+0000","dateStarted":"2017-11-24T15:00:28+0000","dateFinished":"2017-11-24T15:00:29+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3729"},{"text":"%spark.pyspark\n\npredicciones = model.predict(prueba)\nprint 'Debemos prestar:?'\nresultados = validar.zip(predicciones)\nfor resultado in resultados.collect():\n    print resultado\n\nerrorModelo = resultados.map(lambda lp: (lp[0].label - lp[1]) ** 2).sum() / float(prueba.count())\n\nprint '#' * 50\nprint '\\nLa media de errores al cuadrado es: %f' % errorModelo\n","user":"user1","dateUpdated":"2017-11-24T15:00:31+0000","config":{"colWidth":6,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Debemos prestar:?\n(LabeledPoint(1.0, [1274.0,6994.0,1.0,23154.0]), 1.0)\n(LabeledPoint(0.0, [5925.0,26250.0,2.0,49897.0]), 0.0)\n(LabeledPoint(0.0, [5366.0,67421.0,2.0,16723.0]), 0.0)\n(LabeledPoint(1.0, [6433.0,55274.0,4.0,29544.0]), 0.0)\n(LabeledPoint(1.0, [8912.0,70206.0,4.0,21600.0]), 0.0)\n(LabeledPoint(1.0, [7725.0,94930.0,2.0,98868.0]), 1.0)\n(LabeledPoint(1.0, [9857.0,93109.0,1.0,78017.0]), 0.0)\n(LabeledPoint(0.0, [8814.0,40368.0,1.0,74739.0]), 0.0)\n(LabeledPoint(0.0, [9923.0,59155.0,1.0,41322.0]), 0.0)\n(LabeledPoint(0.0, [8140.0,88512.0,3.0,45160.0]), 0.0)\n(LabeledPoint(0.0, [4775.0,55886.0,1.0,62173.0]), 0.0)\n(LabeledPoint(1.0, [906.0,19372.0,2.0,70916.0]), 1.0)\n(LabeledPoint(0.0, [3024.0,27780.0,3.0,74464.0]), 1.0)\n(LabeledPoint(1.0, [3838.0,58489.0,1.0,89779.0]), 0.0)\n(LabeledPoint(0.0, [7267.0,66172.0,3.0,30019.0]), 0.0)\n(LabeledPoint(1.0, [2832.0,41134.0,4.0,89175.0]), 0.0)\n(LabeledPoint(0.0, [3141.0,8125.0,4.0,51378.0]), 1.0)\n(LabeledPoint(0.0, [9749.0,23068.0,1.0,77068.0]), 0.0)\n(LabeledPoint(1.0, [7510.0,39516.0,3.0,57571.0]), 0.0)\n(LabeledPoint(1.0, [1180.0,97653.0,1.0,97668.0]), 0.0)\n(LabeledPoint(0.0, [4179.0,47158.0,0.0,48927.0]), 0.0)\n(LabeledPoint(0.0, [3190.0,98733.0,0.0,66318.0]), 0.0)\n(LabeledPoint(1.0, [4767.0,55876.0,1.0,61964.0]), 0.0)\n(LabeledPoint(1.0, [3588.0,31678.0,2.0,85974.0]), 1.0)\n(LabeledPoint(1.0, [5824.0,56194.0,2.0,81715.0]), 1.0)\n(LabeledPoint(0.0, [6913.0,1128.0,1.0,25241.0]), 0.0)\n(LabeledPoint(0.0, [3773.0,46598.0,3.0,10557.0]), 1.0)\n(LabeledPoint(0.0, [985.0,44803.0,0.0,11913.0]), 1.0)\n(LabeledPoint(1.0, [4364.0,82778.0,2.0,69708.0]), 1.0)\n(LabeledPoint(0.0, [1586.0,959.0,3.0,94681.0]), 1.0)\n(LabeledPoint(0.0, [8369.0,33764.0,0.0,98711.0]), 0.0)\n(LabeledPoint(0.0, [8654.0,60207.0,0.0,94721.0]), 1.0)\n(LabeledPoint(0.0, [9599.0,62820.0,2.0,48363.0]), 0.0)\n(LabeledPoint(1.0, [8220.0,22424.0,4.0,41127.0]), 0.0)\n(LabeledPoint(0.0, [3880.0,78270.0,1.0,90821.0]), 0.0)\n(LabeledPoint(0.0, [638.0,61458.0,1.0,69892.0]), 0.0)\n##################################################\n\nLa media de errores al cuadrado es: 0.416667\n"}]},"apps":[],"jobName":"paragraph_1511528193369_-1898915958","id":"20171124-125633_1747487748","dateCreated":"2017-11-24T12:56:33+0000","dateStarted":"2017-11-24T15:00:31+0000","dateFinished":"2017-11-24T15:00:31+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3730"},{"text":"%spark.pyspark\n\nprint('Modelo de clasificacion obtenido:')\nprint(model.toDebugString())\n","user":"user1","dateUpdated":"2017-11-24T15:07:51+0000","config":{"colWidth":7,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python","tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Modelo de clasificacion obtenido:\nDecisionTreeModel classifier of depth 5 with 19 nodes\n  If (feature 3 <= 12056.0)\n   Predict: 1.0\n  Else (feature 3 > 12056.0)\n   If (feature 0 <= 3656.0)\n    If (feature 1 <= 38194.0)\n     Predict: 1.0\n    Else (feature 1 > 38194.0)\n     If (feature 3 <= 24325.0)\n      Predict: 1.0\n     Else (feature 3 > 24325.0)\n      If (feature 0 <= 3576.0)\n       Predict: 0.0\n      Else (feature 0 > 3576.0)\n       Predict: 1.0\n   Else (feature 0 > 3656.0)\n    If (feature 2 in {1.0})\n     Predict: 0.0\n    Else (feature 2 not in {1.0})\n     If (feature 3 <= 55883.0)\n      If (feature 1 <= 78764.0)\n       Predict: 0.0\n      Else (feature 1 > 78764.0)\n       Predict: 0.0\n     Else (feature 3 > 55883.0)\n      If (feature 1 <= 45343.0)\n       Predict: 0.0\n      Else (feature 1 > 45343.0)\n       Predict: 1.0\n\n"}]},"apps":[],"jobName":"paragraph_1511486320473_1916822390","id":"20171124-011840_130986200","dateCreated":"2017-11-24T01:18:40+0000","dateStarted":"2017-11-24T15:03:44+0000","dateFinished":"2017-11-24T15:03:48+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3731"},{"text":"%md\n### Reutilizar el modelo\nPuedo guardar el modelo para utilizarlo luego en predicciones posteriores:\n","user":"user1","dateUpdated":"2017-11-24T15:14:53+0000","config":{"colWidth":5,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Reutilizar el modelo</h3>\n<p>Puedo guardar el modelo para utilizarlo luego en predicciones posteriores:</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1511536078572_742277899","id":"20171124-150758_1011834176","dateCreated":"2017-11-24T15:07:58+0000","dateStarted":"2017-11-24T15:14:53+0000","dateFinished":"2017-11-24T15:14:53+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3732"},{"text":"%sh\n\nrm -Rf /zeppelin/models/creditos\n","user":"user1","dateUpdated":"2017-11-24T15:16:03+0000","config":{"colWidth":5,"enabled":true,"results":{},"editorSetting":{"language":"sh","editOnDblClick":false},"editorMode":"ace/mode/sh"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1511536187655_-430482721","id":"20171124-150947_831967698","dateCreated":"2017-11-24T15:09:47+0000","dateStarted":"2017-11-24T15:16:03+0000","dateFinished":"2017-11-24T15:16:03+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3733"},{"text":"%spark.pyspark\n\nfrom pyspark.mllib.tree import DecisionTreeModel\n\nmodel.save(sc, '/zeppelin/models/creditos')\nloadedModel = DecisionTreeModel.load(sc, '/zeppelin/models/creditos')\n\nnueva_prediccion = loadedModel.predict([[1274.0,6994.0,1.0,23154.0]])\nprint 'Le podemos prestar? %r ' % nueva_prediccion","user":"user1","dateUpdated":"2017-11-24T15:16:04+0000","config":{"colWidth":5,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Le podemos prestar? 1.0 \n"}]},"apps":[],"jobName":"paragraph_1511527745601_1589806467","id":"20171124-124905_867010342","dateCreated":"2017-11-24T12:49:05+0000","dateStarted":"2017-11-24T15:16:04+0000","dateFinished":"2017-11-24T15:16:05+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3734"},{"text":"%spark.pyspark\n","user":"user1","dateUpdated":"2017-11-24T15:15:00+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1511536500977_2087155906","id":"20171124-151500_2047497324","dateCreated":"2017-11-24T15:15:00+0000","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:3735"}],"name":"/PSL_DS_Training/DecisionTrees","id":"2CZQHNNTZ","angularObjects":{"2CYTRGJ4C:shared_process":[],"2CY4ANXKH:shared_process":[],"2D1FAAA2W:shared_process":[],"2D18CBQ4R:shared_process":[],"2CYWNE1SK:shared_process":[],"2CZ53PD9E:shared_process":[],"2CXMSYMKE:shared_process":[],"2CYXNMRRW:shared_process":[],"2CYC381B1:shared_process":[],"2CYUNTTZY:shared_process":[],"2CYM4X6U4:shared_process":[],"2CXY1FUQK:shared_process":[],"2CY6ZF1J1:shared_process":[],"2CX82UF88:shared_process":[],"2CXNTVNX9:shared_process":[],"2CZHUJN1A:shared_process":[],"2CXFBX3H1::2CZQHNNTZ":[],"2CZSSYREP:shared_process":[],"2CYABBU1U:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}